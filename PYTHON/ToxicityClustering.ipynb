{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy.random import seed\n",
    "seed(1)\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from analysis import *\n",
    "from collections import namedtuple\n",
    "import Metrics\n",
    "from PatientSet import PatientSet\n",
    "from Constants import Constants\n",
    "from dependencies.Boruta import BorutaPy\n",
    "from Clustering import *\n",
    "import re\n",
    "\n",
    "#sklearn dependencies\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import roc_auc_score, adjusted_rand_score\n",
    "from sklearn.ensemble import ExtraTreesClassifier, RandomForestClassifier\n",
    "from sklearn.utils import resample\n",
    "from sklearn.cluster import FeatureAgglomeration\n",
    "\n",
    "#we get like a million deprication errors for some reason with the external libraries\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\git_repos\\CAMP-RT\\PYTHON\\Patient.py:359: RuntimeWarning: invalid value encountered in true_divide\n",
      "  mean_tumor_distances /= tumor_volume\n",
      "D:\\git_repos\\CAMP-RT\\PYTHON\\Patient.py:360: RuntimeWarning: invalid value encountered in true_divide\n",
      "  tumor_position /= tumor_volume\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100 [{0, 1}, {2}]\n",
      "128 [{0}, {1, 2, 3, 4}]\n",
      "notation not accounted for in lymph nodes: R3/R4\n",
      "notation not accounted for in lymph nodes: L2/3\n",
      "notation not accounted for in lymph nodes: R3/4\n",
      "notation not accounted for in lymph nodes: R2/3\n",
      "notation not accounted for in lymph nodes: R2-R4\n",
      "notation not accounted for in lymph nodes: L2/3\n",
      "notation not accounted for in lymph nodes: L2/3\n",
      "notation not accounted for in lymph nodes: L2/3\n",
      "notation not accounted for in lymph nodes: R2/3\n",
      "notation not accounted for in lymph nodes: R2/3/4\n",
      "notation not accounted for in lymph nodes: L2/3\n",
      "notation not accounted for in lymph nodes: L2/3\n",
      "notation not accounted for in lymph nodes: R2/3\n",
      "notation not accounted for in lymph nodes: R2/3\n",
      "notation not accounted for in lymph nodes: R2/3\n",
      "10021 [{0, 1}, {2}]\n",
      "10074 [{0, 1}, {2}]\n",
      "error reading tumor volume for  10091\n",
      "error reading tumor volume for  10148\n",
      "10191 [{0, 1}, {2}]\n",
      "WARNING:tensorflow:From C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\control_flow_ops.py:423: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "\n",
      "patient data loaded...\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#load in the patientset object that has all the patient info\n",
    "db = PatientSet()\n",
    "\n",
    "#add a bunch of features to the object that we'll want to try\n",
    "#so we can use the db.to_dataframe function to get them all in a nice dataframe with one-hot encoding and labels automatically\n",
    "db.discrete_dists = Metrics.discretize(-db.tumor_distances, n_bins = 15, strategy='uniform')\n",
    "db.discrete_volumes = Metrics.discretize(db.volumes, n_bins = 15, strategy='uniform')\n",
    "db.t_volumes = np.array([np.sum([g.volume for g in gtvs]) for gtvs in db.gtvs]).reshape(-1,1)\n",
    "db.tsimdoses = tsim_prediction(db)\n",
    "db.toxicity = db.feeding_tubes + db.aspiration > 0\n",
    "db.xerostima = db.feeding_tubes + db.aspiration > 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext Clustering\n",
    "\n",
    "#parameters for the experiments\n",
    "toxicities_to_test = ['toxicity']\n",
    "\n",
    "#features to test the feature selection on.  should be fields in the patientset we have\n",
    "#we don't cluster on these\n",
    "db.bilateral = db.lateralities == 'B'\n",
    "db.total_volumes = db.volumes.sum(axis = 0)\n",
    "unclusterable_features = ['t_volumes', 'bilateral', 'total_volumes']\n",
    "#we cluster on these (each individually) if feature_clustering is defined,\n",
    "clusterable_features = ['tumor_distances', 'volumes']\n",
    "#number of times to resample and doing feature selection\n",
    "#if n = 1, just use the first result\n",
    "n_samples = 1\n",
    "\n",
    "#type of scaling to use\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "#put some bounds on the features to subset\n",
    "min_features = 2\n",
    "\n",
    "#make this none if you don't want to cluster the features\n",
    "#otherwise give a number of clusters to group them, \n",
    "#should be <33 as of writting this as that is the total included number of organs\n",
    "feature_clustering = None\n",
    "\n",
    "#class used to subset the data, default is what the original paper suggests, roughly\n",
    "boruta = BorutaPy(ExtraTreesClassifier(n_estimators = 600), n_estimators = 2000)\n",
    "\n",
    "#where to save results, put None if you don't want to save\n",
    "save_root = 'data/clustering_results/'\n",
    "\n",
    "#how to decide which clustering method is best.  shoud be 'rand_score' or 'correlation'\n",
    "cluster_metric = 'correlation'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext Clustering\n",
    "from Clustering import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "toxicity\n",
      "['Parotid_Gland_tsimdoses_combined', 'Genioglossus_M_tumor_distances']\n",
      "0.9999999998591886\n",
      "\n",
      "['Parotid_Gland_tsimdoses_combined', 'Genioglossus_M_tumor_distances', 'Lateral_Pterygoid_M_tsimdoses_combined']\n",
      "0.9999999999881237\n",
      "\n",
      "['Parotid_Gland_tsimdoses_combined', 'Genioglossus_M_tumor_distances', 'Lateral_Pterygoid_M_tsimdoses_combined', 'MPC_volumes']\n",
      "0.9999999999985696\n",
      "\n",
      "['Parotid_Gland_tsimdoses_combined', 'Genioglossus_M_tumor_distances', 'Lateral_Pterygoid_M_tsimdoses_combined', 'MPC_volumes', 'Masseter_M_tsimdoses_combined']\n",
      "0.99999999999954\n",
      "\n",
      "['Parotid_Gland_tsimdoses_combined', 'Genioglossus_M_tumor_distances', 'Lateral_Pterygoid_M_tsimdoses_combined', 'MPC_volumes', 'Masseter_M_tsimdoses_combined']\n",
      "Index(['Parotid_Gland_tsimdoses_combined', 'Genioglossus_M_tumor_distances',\n",
      "       'Lateral_Pterygoid_M_tsimdoses_combined', 'MPC_volumes',\n",
      "       'Masseter_M_tsimdoses_combined'],\n",
      "      dtype='object')\n",
      "number of features:  5\n",
      "ward4\n",
      "[[110.   8.]\n",
      " [ 24.  24.]\n",
      " [  0.   1.]\n",
      " [ 32.   1.]]\n",
      "correlation:  6.579045953538654e-11\n",
      "rand score:  0.17806851952526054 \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:52: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    }
   ],
   "source": [
    "#our actual experiment, try to find correlations using the boruta method and such\n",
    "feature_list = []\n",
    "supports_dict = {}\n",
    "for tox_name in toxicities_to_test:\n",
    "    print(tox_name)\n",
    "    toxicity = getattr(db, tox_name) > 0\n",
    "    \n",
    "    #remove eyeball stuff from the candidates since those are missing in some patients\n",
    "    #and it messes up the feature selection due to that noise\n",
    "    organs = copy(Constants.organ_list)\n",
    "    for o in Constants.organ_list:\n",
    "        if re.search('Eyeball', o) is not None:\n",
    "            organs.remove(o)\n",
    "    \n",
    "    base = db.to_dataframe(unclusterable_features)\n",
    "    for f in clusterable_features:\n",
    "        temp_data = db.to_dataframe([f], \n",
    "                               merge_mirrored_organs = True, \n",
    "                               organ_list = organs)\n",
    "        if feature_clustering is not None:\n",
    "            temp_data = FeatureClusterer(feature_clustering).fit_predict(temp_data)\n",
    "        base = base.join(temp_data, how = 'inner')\n",
    "    \n",
    "    train = db.to_dataframe(['doses'],\n",
    "                           merge_mirrored_organs = True,\n",
    "                           organ_list = organs)\n",
    "    test = db.to_dataframe(['tsimdoses'],\n",
    "                           merge_mirrored_organs = True,\n",
    "                           organ_list = organs)\n",
    "    if feature_clustering is not None:\n",
    "        fc = FeatureClusterer(feature_clustering)\n",
    "        train = fc.fit_predict(train)\n",
    "        test = fc.predict(test)\n",
    "    train = train.join(base, how = 'inner')\n",
    "    test = test.join(base, how = 'inner')\n",
    "    feature_selector = FeatureClusterSelector(n_samples = n_samples).fit(train, toxicity)\n",
    "    to_use = feature_selector.transform(test)\n",
    "\n",
    "    print(to_use.columns)\n",
    "        \n",
    "    print('number of features: ', to_use.shape[1])\n",
    "\n",
    "    #we're going to try a bunch of different clusterings and look at the best result\n",
    "    clustering = get_optimal_clustering(to_use.values, \n",
    "                                        toxicity,\n",
    "                                        metric = cluster_metric)\n",
    "    print(clustering[1].method)\n",
    "    print(get_contingency_table(clustering[0], toxicity))\n",
    "    print('correlation: ', clustering[1].correlation)\n",
    "    print('rand score: ', clustering[1].rand_score,'\\n')\n",
    "\n",
    "    to_use['cluster_labels'] = clustering[0]\n",
    "#     print(best_features.columns)\n",
    "    to_use.index.rename('Dummy.ID', inplace = True)\n",
    "    feature_list.append(to_use)\n",
    "    if save_root is not None:\n",
    "        best_features.to_csv(save_root\n",
    "                     + 'boruta_features_k='\n",
    "                     + str(n_best_clusters)\n",
    "                     + '_p=' + '{:.3e}'.format(best_results.correlation)\n",
    "                     + '_toxicity=' + tox_name + '.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\frame.py:3940: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  errors=errors)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Parotid_Gland_tsimdoses_combined', 'Genioglossus_M_tumor_distances',\n",
      "       'Lateral_Pterygoid_M_tsimdoses_combined', 'MPC_volumes',\n",
      "       'Masseter_M_tsimdoses_combined'],\n",
      "      dtype='object')\n",
      "ward4\n",
      "[[110.   8.]\n",
      " [ 24.  24.]\n",
      " [  0.   1.]\n",
      " [ 32.   1.]]\n",
      "correlation:  6.579045953538654e-11\n",
      "rand score:  0.17806851952526054 \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:18: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    }
   ],
   "source": [
    "#get all the features found before and put them together\n",
    "combined_df = feature_list[0]\n",
    "if len(feature_list) > 1:\n",
    "    for i in range(1, len(feature_list)):\n",
    "        df2 = feature_list[i]\n",
    "        to_drop = list(set(combined_df.columns).intersection(set(df2.columns)))\n",
    "        if len(to_drop) == df2.shape[1]:\n",
    "            continue\n",
    "        df2 = df2.drop(to_drop, axis = 1)\n",
    "        combined_df = pd.merge(combined_df, df2, on = 'Dummy.ID')\n",
    "combined_df.drop('cluster_labels', axis = 1, inplace = True)\n",
    "print(combined_df.columns)\n",
    "combined_clusters = get_optimal_clustering(combined_df.values, db.toxicity)\n",
    "print(combined_clusters[1].method)\n",
    "print(get_contingency_table(combined_clusters[0], toxicity))\n",
    "print('correlation: ', combined_clusters[1].correlation)\n",
    "print('rand score: ', combined_clusters[1].rand_score, '\\n')\n",
    "combined_df['cluster_labels'] = combined_clusters[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "metadata": {},
   "outputs": [
    {
     "ename": "PermissionError",
     "evalue": "[Errno 13] Permission denied: 'data/clustering_results/forwardSelectionClustering.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mPermissionError\u001b[0m                           Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-307-d1a9d63c9cb2>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0msave_root\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m     combined_df.to_csv(save_root\n\u001b[1;32m----> 3\u001b[1;33m                  + 'forwardSelectionClustering.csv')\n\u001b[0m",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36mto_csv\u001b[1;34m(self, path_or_buf, sep, na_rep, float_format, columns, header, index, index_label, mode, encoding, compression, quoting, quotechar, line_terminator, chunksize, tupleize_cols, date_format, doublequote, escapechar, decimal)\u001b[0m\n\u001b[0;32m   3018\u001b[0m                                  \u001b[0mdoublequote\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdoublequote\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3019\u001b[0m                                  escapechar=escapechar, decimal=decimal)\n\u001b[1;32m-> 3020\u001b[1;33m         \u001b[0mformatter\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msave\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3021\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3022\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mpath_or_buf\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\io\\formats\\csvs.py\u001b[0m in \u001b[0;36msave\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    155\u001b[0m             f, handles = _get_handle(self.path_or_buf, self.mode,\n\u001b[0;32m    156\u001b[0m                                      \u001b[0mencoding\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mencoding\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 157\u001b[1;33m                                      compression=self.compression)\n\u001b[0m\u001b[0;32m    158\u001b[0m             \u001b[0mclose\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    159\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\io\\common.py\u001b[0m in \u001b[0;36m_get_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text)\u001b[0m\n\u001b[0;32m    422\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0mencoding\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    423\u001b[0m             \u001b[1;31m# Python 3 and encoding\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 424\u001b[1;33m             \u001b[0mf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath_or_buf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mencoding\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnewline\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    425\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0mis_text\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    426\u001b[0m             \u001b[1;31m# Python 3 and no explicit encoding\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mPermissionError\u001b[0m: [Errno 13] Permission denied: 'data/clustering_results/forwardSelectionClustering.csv'"
     ]
    }
   ],
   "source": [
    "if save_root is not None:\n",
    "    combined_df.to_csv(save_root\n",
    "                 + 'forwardSelectionClustering.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0004257957682429409"
      ]
     },
     "execution_count": 305,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fisher_exact_test(AgglomerativeClustering(4).fit_predict(combined_df.values), db.toxicity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
